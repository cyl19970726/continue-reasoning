# LLMäº‹ä»¶å¤„ç†æœºåˆ¶ (LLM Event Handling)

## æ¦‚è¿°

LLMäº‹ä»¶å¤„ç†æ˜¯Continue-Reasoningäº‹ä»¶é©±åŠ¨æ¶æ„çš„æ ¸å¿ƒéƒ¨åˆ†ï¼Œè´Ÿè´£å¤„ç†å¤§è¯­è¨€æ¨¡å‹çš„è°ƒç”¨ã€æµå¼å“åº”ã€å·¥å…·è°ƒç”¨å’Œæ€è€ƒè¿‡ç¨‹ã€‚é€šè¿‡äº‹ä»¶æœºåˆ¶ï¼Œç³»ç»Ÿå®ç°äº†å¯¹LLMäº¤äº’è¿‡ç¨‹çš„å®Œæ•´è¿½è¸ªå’Œå®æ—¶åé¦ˆã€‚

## LLMäº‹ä»¶ç±»å‹ä½“ç³»

### åŸºç¡€LLMäº‹ä»¶æ¥å£

```typescript
export interface LLMEvent extends BaseEvent {
    type: 
        | 'llm.call.started'           // LLMè°ƒç”¨å¼€å§‹
        | 'llm.call.completed'         // LLMè°ƒç”¨å®Œæˆ
        | 'llm.text.delta'             // æ–‡æœ¬å¢é‡è¾“å‡ºï¼ˆæµå¼ï¼‰
        | 'llm.text.completed'         // æ–‡æœ¬ç”Ÿæˆå®Œæˆ
        | 'llm.tool.call.started'      // å·¥å…·è°ƒç”¨å¼€å§‹
        | 'llm.tool.call.completed'    // å·¥å…·è°ƒç”¨å®Œæˆ
        | 'llm.thinking.started'       // æ€è€ƒå¼€å§‹
        | 'llm.thinking.completed';    // æ€è€ƒå®Œæˆ
        
    stepIndex?: number;
    data: {
        // åŸºç¡€å†…å®¹
        content?: string;              // æ–‡æœ¬å†…å®¹
        chunkIndex?: number;           // å—ç´¢å¼•
        outputIndex?: number;          // è¾“å‡ºç´¢å¼•
        
        // å·¥å…·è°ƒç”¨ç›¸å…³
        toolCall?: ToolCallParams;     // å·¥å…·è°ƒç”¨å‚æ•°
        result?: any;                  // è°ƒç”¨ç»“æœ
        error?: Error;                 // é”™è¯¯ä¿¡æ¯
        
        // æ€è€ƒç›¸å…³
        thought?: string;              // æ€è€ƒå†…å®¹
        confidence?: number;           // ç½®ä¿¡åº¦
        finalThought?: string;         // æœ€ç»ˆæ€è€ƒ
        
        // è°ƒç”¨æ¨¡å¼æ ‡è¯†
        isStreaming?: boolean;         // æ˜¯å¦ä¸ºæµå¼è°ƒç”¨
        callType?: 'async' | 'stream'; // è°ƒç”¨ç±»å‹
        
        // å®¢æˆ·ç«¯å…¼å®¹å±æ€§
        stepIndex?: number;            // æ­¥éª¤ç´¢å¼•
        delta?: string;                // æ–‡æœ¬å¢é‡
        text?: string;                 // å®Œæ•´æ–‡æœ¬
    };
}
```

## LLMäº‹ä»¶æµå¤„ç†æ¨¡å¼

### 1. æµå¼è°ƒç”¨äº‹ä»¶æµ (StreamAgent)

```mermaid
sequenceDiagram
    participant Agent as StreamAgent
    participant LLM as LLM Wrapper
    participant EventBus as EventBus
    participant Client as Client/UI
    
    Note over Agent,Client: æµå¼LLMè°ƒç”¨æµç¨‹
    
    Agent->>EventBus: publish(llm.call.started)
    EventBus->>Client: è°ƒç”¨å¼€å§‹é€šçŸ¥
    
    Agent->>LLM: callStream(prompt, tools)
    
    loop æµå¼å“åº”å¤„ç†
        LLM->>Agent: chunk(content)
        Agent->>EventBus: publish(llm.text.delta)
        EventBus->>Client: å®æ—¶æ–‡æœ¬æ›´æ–°
        
        alt æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨
            LLM->>Agent: chunk(toolCall)
            Agent->>EventBus: publish(llm.tool.call.started)
            EventBus->>Client: å·¥å…·è°ƒç”¨å¼€å§‹
            
            Agent->>Agent: executeToolCall()
            Agent->>EventBus: publish(llm.tool.call.completed)
            EventBus->>Client: å·¥å…·è°ƒç”¨å®Œæˆ
        end
        
        alt æ£€æµ‹åˆ°æ€è€ƒè¿‡ç¨‹
            LLM->>Agent: chunk(thinking)
            Agent->>EventBus: publish(llm.thinking.started)
            EventBus->>Client: æ€è€ƒè¿‡ç¨‹å¼€å§‹
            
            Agent->>EventBus: publish(llm.thinking.completed)
            EventBus->>Client: æ€è€ƒå®Œæˆ
        end
    end
    
    Agent->>EventBus: publish(llm.text.completed)
    EventBus->>Client: æ–‡æœ¬ç”Ÿæˆå®Œæˆ
    
    Agent->>EventBus: publish(llm.call.completed)
    EventBus->>Client: è°ƒç”¨å®Œæˆé€šçŸ¥
```

### 2. å¼‚æ­¥è°ƒç”¨äº‹ä»¶æµ (AsyncAgent)

```mermaid
sequenceDiagram
    participant Agent as AsyncAgent
    participant LLM as LLM Wrapper
    participant EventBus as EventBus
    participant Client as Client/UI
    
    Note over Agent,Client: å¼‚æ­¥LLMè°ƒç”¨æµç¨‹
    
    Agent->>EventBus: publish(llm.call.started)
    EventBus->>Client: è°ƒç”¨å¼€å§‹é€šçŸ¥
    
    Agent->>LLM: callAsync(prompt, tools)
    
    Note over LLM: ç­‰å¾…å®Œæ•´å“åº”
    
    LLM->>Agent: å®Œæ•´å“åº”ç»“æœ
    
    alt åŒ…å«å·¥å…·è°ƒç”¨
        Agent->>EventBus: publish(llm.tool.call.started)
        EventBus->>Client: å·¥å…·è°ƒç”¨å¼€å§‹
        
        Agent->>Agent: executeToolCall()
        Agent->>EventBus: publish(llm.tool.call.completed)
        EventBus->>Client: å·¥å…·è°ƒç”¨å®Œæˆ
    end
    
    Agent->>EventBus: publish(llm.text.completed)
    EventBus->>Client: å®Œæ•´æ–‡æœ¬è¾“å‡º
    
    Agent->>EventBus: publish(llm.call.completed)
    EventBus->>Client: è°ƒç”¨å®Œæˆé€šçŸ¥
```

## LLMäº‹ä»¶æ˜ å°„å™¨ (LLMEventMapper)

### æ ¸å¿ƒåŠŸèƒ½

LLMEventMapperè´Ÿè´£å°†åŸå§‹çš„LLMå“åº”æ•°æ®è½¬æ¢ä¸ºæ ‡å‡†åŒ–çš„äº‹ä»¶æ ¼å¼ï¼š

```typescript
export class LLMEventMapper {
    /**
     * å°†æµå¼æ•°æ®å—è½¬æ¢ä¸ºäº‹ä»¶
     */
    static convertChunkToEvents(
        chunk: any,
        stepIndex: number,
        sessionId?: string,
        source: string = 'Agent'
    ): LLMEvent[] {
        const events: LLMEvent[] = [];
        
        // 1. å¤„ç†æ–‡æœ¬å†…å®¹
        if (chunk.content) {
            events.push({
                type: 'llm.text.delta',
                timestamp: Date.now(),
                source,
                stepIndex,
                sessionId,
                data: {
                    content: chunk.content,
                    delta: chunk.content,
                    chunkIndex: chunk.chunkIndex || 0,
                    stepIndex,
                    isStreaming: true,
                    callType: 'stream'
                }
            });
        }
        
        // 2. å¤„ç†å·¥å…·è°ƒç”¨
        if (chunk.toolCall) {
            events.push({
                type: 'llm.tool.call.started',
                timestamp: Date.now(),
                source,
                stepIndex,
                sessionId,
                data: {
                    toolCall: chunk.toolCall,
                    stepIndex,
                    isStreaming: true
                }
            });
        }
        
        // 3. å¤„ç†æ€è€ƒè¿‡ç¨‹
        if (chunk.thinking) {
            events.push({
                type: 'llm.thinking.started',
                timestamp: Date.now(),
                source,
                stepIndex,
                sessionId,
                data: {
                    thought: chunk.thinking,
                    stepIndex,
                    confidence: chunk.confidence
                }
            });
        }
        
        return events;
    }
    
    /**
     * åˆ›å»ºæµå¼è°ƒç”¨äº‹ä»¶ç”Ÿæˆå™¨
     */
    static createStreamCallEvents(
        stepIndex: number,
        sessionId?: string,
        source: string = 'Agent'
    ) {
        return {
            started: () => ({
                type: 'llm.call.started' as const,
                timestamp: Date.now(),
                source,
                stepIndex,
                sessionId,
                data: {
                    callType: 'stream' as const,
                    isStreaming: true,
                    stepIndex
                }
            }),
            
            completed: () => ({
                type: 'llm.call.completed' as const,
                timestamp: Date.now(),
                source,
                stepIndex,
                sessionId,
                data: {
                    callType: 'stream' as const,
                    isStreaming: true,
                    stepIndex
                }
            }),
            
            textCompleted: (fullText: string) => ({
                type: 'llm.text.completed' as const,
                timestamp: Date.now(),
                source,
                stepIndex,
                sessionId,
                data: {
                    content: fullText,
                    text: fullText,
                    stepIndex,
                    isStreaming: true
                }
            })
        };
    }
}
```

## å…·ä½“å®ç°ç¤ºä¾‹

### 1. StreamAgentä¸­çš„LLMäº‹ä»¶å¤„ç†

```typescript
export class StreamAgent extends BaseAgent {
    private async processStreamResponse(
        prompt: string,
        toolDefs: any[],
        stepIndex: number
    ): Promise<void> {
        // åˆ›å»ºäº‹ä»¶ç”Ÿæˆå™¨
        const llmEvents = LLMEventMapper.createStreamCallEvents(
            stepIndex,
            this.currentSessionId,
            `agent.${this.id}`
        );

        // å‘å¸ƒè°ƒç”¨å¼€å§‹äº‹ä»¶
        await this.eventBus.publish(llmEvents.started());

        try {
            // åˆå§‹åŒ–æ­¥éª¤æ•°æ®å®¹å™¨
            this.currentStepData = {
                stepIndex,
                rawText: '',
                toolCalls: [],
                toolExecutionResults: [],
                toolExecutionPromises: [],
                isComplete: false
            };

            // æ‰§è¡Œæµå¼è°ƒç”¨
            await this.llm.callStream(prompt, toolDefs, async (chunk: any) => {
                await this.handleStreamChunk(chunk, stepIndex, 
                    this.currentStepData?.chunkCount || 0, llmEvents);
                
                if (this.currentStepData) {
                    this.currentStepData.chunkCount = (this.currentStepData.chunkCount || 0) + 1;
                }
            });

            // ç­‰å¾…å·¥å…·æ‰§è¡Œå®Œæˆ
            if (this.currentStepData?.toolExecutionPromises.length > 0) {
                await Promise.all(this.currentStepData.toolExecutionPromises);
            }

            // å‘å¸ƒæ–‡æœ¬å®Œæˆäº‹ä»¶
            await this.eventBus.publish(llmEvents.textCompleted(
                this.currentStepData?.rawText || ''
            ));

            // å‘å¸ƒè°ƒç”¨å®Œæˆäº‹ä»¶
            await this.eventBus.publish(llmEvents.completed());

            // æ ‡è®°æ­¥éª¤å®Œæˆ
            if (this.currentStepData) {
                this.currentStepData.isComplete = true;
            }

        } catch (error) {
            // å‘å¸ƒé”™è¯¯äº‹ä»¶
            await this.eventBus.publish({
                type: 'error.occurred',
                timestamp: Date.now(),
                source: `agent.${this.id}`,
                stepIndex,
                sessionId: this.currentSessionId,
                data: {
                    error: error instanceof Error ? error : new Error(String(error)),
                    context: { stepIndex, prompt: prompt.substring(0, 100) }
                }
            });
            throw error;
        }
    }

    private async handleStreamChunk(
        chunk: any,
        stepIndex: number,
        chunkIndex: number,
        llmEvents: any
    ): Promise<void> {
        logger.debug(`[StreamAgent] å¤„ç†æµå¼æ•°æ®å— ${chunkIndex}`, chunk);

        // è½¬æ¢ä¸ºæ ‡å‡†äº‹ä»¶
        const events = LLMEventMapper.convertChunkToEvents(
            chunk, 
            stepIndex, 
            this.currentSessionId, 
            `agent.${this.id}`
        );

        // å‘å¸ƒæ‰€æœ‰äº‹ä»¶
        for (const event of events) {
            await this.eventBus.publish(event);
        }

        // æ›´æ–°æ­¥éª¤æ•°æ®
        if (this.currentStepData) {
            if (chunk.content) {
                this.currentStepData.rawText += chunk.content;
            }

            if (chunk.toolCall) {
                this.currentStepData.toolCalls = this.currentStepData.toolCalls || [];
                this.currentStepData.toolCalls.push(chunk.toolCall);
                
                // å¼‚æ­¥æ‰§è¡Œå·¥å…·è°ƒç”¨
                const toolPromise = this.handleToolCallExecution(chunk.toolCall, stepIndex);
                this.currentStepData.toolExecutionPromises.push(toolPromise);
            }
        }
    }
}
```

### 2. AsyncAgentä¸­çš„LLMäº‹ä»¶å¤„ç†

```typescript
export class AsyncAgent extends BaseAgent {
    private async processAsyncResponse(
        prompt: string,
        toolDefs: any[],
        stepIndex: number
    ): Promise<void> {
        // å‘å¸ƒè°ƒç”¨å¼€å§‹äº‹ä»¶
        await this.eventBus.publish({
            type: 'llm.call.started',
            timestamp: Date.now(),
            source: `agent.${this.id}`,
            stepIndex,
            sessionId: this.currentSessionId,
            data: {
                callType: 'async',
                isStreaming: false,
                stepIndex
            }
        });

        try {
            // æ‰§è¡Œå¼‚æ­¥è°ƒç”¨
            const response = await this.llm.callAsync(prompt, toolDefs);
            
            // åˆå§‹åŒ–æ­¥éª¤æ•°æ®
            this.currentStepData = {
                stepIndex,
                rawText: response.content || '',
                toolCalls: [],
                toolExecutionResults: [],
                toolExecutionPromises: [],
                isComplete: false
            };

            // å¤„ç†å·¥å…·è°ƒç”¨ï¼ˆå¦‚æœæœ‰ï¼‰
            if (response.toolCalls && response.toolCalls.length > 0) {
                this.currentStepData.toolCalls = response.toolCalls;
                
                for (const toolCall of response.toolCalls) {
                    // å‘å¸ƒå·¥å…·è°ƒç”¨å¼€å§‹äº‹ä»¶
                    await this.eventBus.publish({
                        type: 'llm.tool.call.started',
                        timestamp: Date.now(),
                        source: `agent.${this.id}`,
                        stepIndex,
                        sessionId: this.currentSessionId,
                        data: {
                            toolCall,
                            stepIndex
                        }
                    });
                    
                    // æ‰§è¡Œå·¥å…·è°ƒç”¨
                    const toolPromise = this.handleToolCallExecution(toolCall, stepIndex);
                    this.currentStepData.toolExecutionPromises.push(toolPromise);
                }
                
                // ç­‰å¾…æ‰€æœ‰å·¥å…·æ‰§è¡Œå®Œæˆ
                await Promise.all(this.currentStepData.toolExecutionPromises);
            }

            // å‘å¸ƒæ–‡æœ¬å®Œæˆäº‹ä»¶
            await this.eventBus.publish({
                type: 'llm.text.completed',
                timestamp: Date.now(),
                source: `agent.${this.id}`,
                stepIndex,
                sessionId: this.currentSessionId,
                data: {
                    content: this.currentStepData.rawText,
                    text: this.currentStepData.rawText,
                    stepIndex,
                    isStreaming: false
                }
            });

            // å‘å¸ƒè°ƒç”¨å®Œæˆäº‹ä»¶
            await this.eventBus.publish({
                type: 'llm.call.completed',
                timestamp: Date.now(),
                source: `agent.${this.id}`,
                stepIndex,
                sessionId: this.currentSessionId,
                data: {
                    callType: 'async',
                    isStreaming: false,
                    stepIndex
                }
            });

            // æ ‡è®°å®Œæˆ
            this.currentStepData.isComplete = true;

        } catch (error) {
            // å‘å¸ƒé”™è¯¯äº‹ä»¶
            await this.eventBus.publish({
                type: 'error.occurred',
                timestamp: Date.now(),
                source: `agent.${this.id}`,
                stepIndex,
                sessionId: this.currentSessionId,
                data: {
                    error: error instanceof Error ? error : new Error(String(error)),
                    context: { stepIndex, callType: 'async' }
                }
            });
            throw error;
        }
    }
}
```

## å®¢æˆ·ç«¯LLMäº‹ä»¶å¤„ç†

### SimpleClientä¸­çš„LLMäº‹ä»¶è®¢é˜…

```typescript
export class SimpleClient implements IClient {
    private setupLLMEventListeners(): void {
        if (!this.eventBus) return;

        // 1. LLMè°ƒç”¨å¼€å§‹ - æ˜¾ç¤ºåŠ è½½çŠ¶æ€
        this.eventBus.subscribe('llm.call.started', (event) => {
            if (event.type === 'llm.call.started') {
                console.log(`ğŸ¤– LLMè°ƒç”¨å¼€å§‹ (æ­¥éª¤ ${event.stepIndex})`);
                this.showLoadingState(event.stepIndex || 0);
            }
        });

        // 2. æ–‡æœ¬å¢é‡ - å®æ—¶æ›´æ–°UI
        this.eventBus.subscribe('llm.text.delta', (event) => {
            if (event.type === 'llm.text.delta' && 
                event.data?.stepIndex !== undefined && 
                event.data?.chunkIndex !== undefined && 
                event.data?.delta) {
                
                this.onLLMTextDelta(
                    event.data.stepIndex, 
                    event.data.chunkIndex, 
                    event.data.delta
                );
            }
        });

        // 3. å·¥å…·è°ƒç”¨å¼€å§‹ - æ˜¾ç¤ºå·¥å…·æ‰§è¡ŒçŠ¶æ€
        this.eventBus.subscribe('llm.tool.call.started', (event) => {
            if (event.type === 'llm.tool.call.started' && event.data?.toolCall) {
                console.log(`ğŸ”§ æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨: ${event.data.toolCall.name}`);
                this.showToolCallStarted(event.data.toolCall);
            }
        });

        // 4. å·¥å…·è°ƒç”¨å®Œæˆ - æ›´æ–°å·¥å…·çŠ¶æ€
        this.eventBus.subscribe('llm.tool.call.completed', (event) => {
            if (event.type === 'llm.tool.call.completed') {
                console.log(`âœ… å·¥å…·è°ƒç”¨å®Œæˆ`);
                this.showToolCallCompleted();
            }
        });

        // 5. æ€è€ƒè¿‡ç¨‹ - æ˜¾ç¤ºAIæ€è€ƒçŠ¶æ€
        this.eventBus.subscribe('llm.thinking.started', (event) => {
            if (event.type === 'llm.thinking.started' && event.data?.thought) {
                console.log(`ğŸ’­ AIæ€è€ƒ: ${event.data.thought}`);
                this.showThinkingProcess(event.data.thought, event.data?.confidence);
            }
        });

        // 6. æ–‡æœ¬å®Œæˆ - å®Œæ•´è¾“å‡º
        this.eventBus.subscribe('llm.text.completed', (event) => {
            if (event.type === 'llm.text.completed' && event.data?.text) {
                this.onLLMTextDone(
                    event.data.stepIndex || 0, 
                    0, 
                    event.data.text
                );
            }
        });

        // 7. è°ƒç”¨å®Œæˆ - éšè—åŠ è½½çŠ¶æ€
        this.eventBus.subscribe('llm.call.completed', (event) => {
            if (event.type === 'llm.call.completed') {
                console.log(`âœ… LLMè°ƒç”¨å®Œæˆ (æ­¥éª¤ ${event.stepIndex})`);
                this.hideLoadingState(event.stepIndex || 0);
            }
        });
    }

    private showLoadingState(stepIndex: number): void {
        // æ˜¾ç¤ºåŠ è½½åŠ¨ç”»æˆ–è¿›åº¦æŒ‡ç¤ºå™¨
        console.log(`ğŸ”„ æ­¥éª¤ ${stepIndex} - LLMå¤„ç†ä¸­...`);
    }

    private hideLoadingState(stepIndex: number): void {
        // éšè—åŠ è½½çŠ¶æ€
        console.log(`âœ… æ­¥éª¤ ${stepIndex} - LLMå¤„ç†å®Œæˆ`);
    }

    private showToolCallStarted(toolCall: any): void {
        // æ˜¾ç¤ºå·¥å…·æ‰§è¡ŒçŠ¶æ€
        console.log(`ğŸ”§ æ‰§è¡Œå·¥å…·: ${toolCall.name}`);
    }

    private showToolCallCompleted(): void {
        // å·¥å…·æ‰§è¡Œå®Œæˆåé¦ˆ
        console.log(`âœ… å·¥å…·æ‰§è¡Œå®Œæˆ`);
    }

    private showThinkingProcess(thought: string, confidence?: number): void {
        // æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹
        const confidenceText = confidence ? ` (ç½®ä¿¡åº¦: ${confidence})` : '';
        console.log(`ğŸ’­ æ€è€ƒ${confidenceText}: ${thought}`);
    }
}
```

## LLMäº‹ä»¶æ€§èƒ½ä¼˜åŒ–

### 1. æ–‡æœ¬å¢é‡äº‹ä»¶æ‰¹å¤„ç†

å¯¹äºé«˜é¢‘çš„æ–‡æœ¬å¢é‡äº‹ä»¶ï¼Œå¯ä»¥å®ç°æ‰¹å¤„ç†ä¼˜åŒ–ï¼š

```typescript
class LLMTextDeltaBatcher {
    private pendingDeltas: Array<{
        stepIndex: number;
        chunkIndex: number;
        content: string;
        timestamp: number;
    }> = [];
    
    private batchTimer?: NodeJS.Timeout;
    private readonly batchWindowMs = 50; // 50msæ‰¹å¤„ç†çª—å£
    
    constructor(private eventBus: IEventBus, private source: string) {}
    
    addTextDelta(stepIndex: number, chunkIndex: number, content: string): void {
        this.pendingDeltas.push({
            stepIndex,
            chunkIndex,
            content,
            timestamp: Date.now()
        });
        
        if (!this.batchTimer) {
            this.batchTimer = setTimeout(() => {
                this.flushBatch();
            }, this.batchWindowMs);
        }
    }
    
    private flushBatch(): void {
        if (this.pendingDeltas.length === 0) return;
        
        // åˆå¹¶è¿ç»­çš„æ–‡æœ¬å¢é‡
        const mergedContent = this.pendingDeltas
            .map(delta => delta.content)
            .join('');
        
        const firstDelta = this.pendingDeltas[0];
        const lastDelta = this.pendingDeltas[this.pendingDeltas.length - 1];
        
        // å‘å¸ƒåˆå¹¶åçš„äº‹ä»¶
        this.eventBus.publish({
            type: 'llm.text.delta',
            timestamp: lastDelta.timestamp,
            source: this.source,
            stepIndex: firstDelta.stepIndex,
            data: {
                content: mergedContent,
                delta: mergedContent,
                chunkIndex: firstDelta.chunkIndex,
                stepIndex: firstDelta.stepIndex,
                batchSize: this.pendingDeltas.length
            }
        });
        
        // æ¸…ç†
        this.pendingDeltas = [];
        this.batchTimer = undefined;
    }
}
```

### 2. äº‹ä»¶è¿‡æ»¤ä¼˜åŒ–

```typescript
// åªè®¢é˜…å½“å‰æ´»è·ƒæ­¥éª¤çš„äº‹ä»¶
const currentStepFilter = { stepIndex: this.currentStepIndex };

this.eventBus.subscribe('llm.text.delta', this.handleTextDelta, currentStepFilter);
this.eventBus.subscribe('llm.tool.call.started', this.handleToolCall, currentStepFilter);

// åªè®¢é˜…ç‰¹å®šä¼šè¯çš„äº‹ä»¶
const sessionFilter = { sessionId: this.currentSessionId };

this.eventBus.subscribe([
    'llm.call.started',
    'llm.call.completed'
], this.handleLLMLifecycle, sessionFilter);
```

## é”™è¯¯å¤„ç†å’Œæ¢å¤

### LLMè°ƒç”¨é”™è¯¯å¤„ç†

```typescript
export class LLMErrorHandler {
    constructor(private eventBus: IEventBus) {
        this.setupErrorSubscriptions();
    }
    
    private setupErrorSubscriptions(): void {
        // ç›‘å¬æ‰€æœ‰LLMç›¸å…³é”™è¯¯
        this.eventBus.subscribe('error.occurred', async (event) => {
            if (event.source?.includes('agent') && event.data?.context?.stepIndex !== undefined) {
                await this.handleLLMError(event);
            }
        });
    }
    
    private async handleLLMError(event: ErrorEvent): Promise<void> {
        const error = event.data.error;
        const context = event.data.context;
        
        console.error(`âŒ LLMé”™è¯¯ (æ­¥éª¤ ${context.stepIndex}):`, error);
        
        // æ ¹æ®é”™è¯¯ç±»å‹å†³å®šæ¢å¤ç­–ç•¥
        if (this.isRetryableError(error)) {
            // å‘å¸ƒé‡è¯•äº‹ä»¶
            await this.eventBus.publish({
                type: 'llm.call.retry',
                timestamp: Date.now(),
                source: 'ErrorHandler',
                stepIndex: context.stepIndex,
                data: {
                    originalError: error,
                    retryCount: context.retryCount || 0
                }
            });
        } else {
            // å‘å¸ƒä¸å¯æ¢å¤é”™è¯¯äº‹ä»¶
            await this.eventBus.publish({
                type: 'llm.call.failed',
                timestamp: Date.now(),
                source: 'ErrorHandler',
                stepIndex: context.stepIndex,
                data: {
                    error,
                    fatal: true
                }
            });
        }
    }
    
    private isRetryableError(error: any): boolean {
        const errorStr = String(error);
        return errorStr.includes('rate limit') || 
               errorStr.includes('timeout') || 
               errorStr.includes('network');
    }
}
```

## è°ƒè¯•å’Œç›‘æ§

### LLMäº‹ä»¶ç›‘æ§é¢æ¿

```typescript
class LLMEventMonitor {
    private stats = {
        totalCalls: 0,
        streamingCalls: 0,
        asyncCalls: 0,
        toolCalls: 0,
        errors: 0,
        averageResponseTime: 0
    };
    
    constructor(private eventBus: IEventBus) {
        this.setupMonitoring();
    }
    
    private setupMonitoring(): void {
        // ç›‘æ§LLMè°ƒç”¨å¼€å§‹
        this.eventBus.subscribe('llm.call.started', (event) => {
            this.stats.totalCalls++;
            if (event.data?.callType === 'stream') {
                this.stats.streamingCalls++;
            } else {
                this.stats.asyncCalls++;
            }
        });
        
        // ç›‘æ§å·¥å…·è°ƒç”¨
        this.eventBus.subscribe('llm.tool.call.started', () => {
            this.stats.toolCalls++;
        });
        
        // ç›‘æ§é”™è¯¯
        this.eventBus.subscribe('error.occurred', (event) => {
            if (event.source?.includes('agent')) {
                this.stats.errors++;
            }
        });
        
        // å®šæœŸè¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        setInterval(() => {
            this.printStats();
        }, 30000); // æ¯30ç§’
    }
    
    private printStats(): void {
        console.log('ğŸ“Š LLMäº‹ä»¶ç»Ÿè®¡:', {
            totalCalls: this.stats.totalCalls,
            streamingCalls: this.stats.streamingCalls,
            asyncCalls: this.stats.asyncCalls,
            toolCalls: this.stats.toolCalls,
            errors: this.stats.errors,
            errorRate: `${((this.stats.errors / this.stats.totalCalls) * 100).toFixed(2)}%`
        });
    }
}
```

## æœ€ä½³å®è·µæ€»ç»“

### 1. äº‹ä»¶å‘å¸ƒåŸåˆ™

- **åŠæ—¶å‘å¸ƒ**: åœ¨LLMäº¤äº’çš„å…³é”®èŠ‚ç‚¹ç«‹å³å‘å¸ƒäº‹ä»¶
- **æ•°æ®å®Œæ•´**: ç¡®ä¿äº‹ä»¶æ•°æ®åŒ…å«è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
- **é”™è¯¯å¤„ç†**: æ‰€æœ‰å¼‚å¸¸éƒ½åº”è½¬æ¢ä¸ºé”™è¯¯äº‹ä»¶

### 2. äº‹ä»¶è®¢é˜…åŸåˆ™

- **ç±»å‹å®‰å…¨**: ä½¿ç”¨ç±»å‹å®ˆå«éªŒè¯äº‹ä»¶æ•°æ®
- **è¿‡æ»¤ä¼˜åŒ–**: ä½¿ç”¨äº‹ä»¶è¿‡æ»¤å‡å°‘ä¸å¿…è¦çš„å¤„ç†
- **èµ„æºç®¡ç†**: åŠæ—¶æ¸…ç†äº‹ä»¶è®¢é˜…ï¼Œé¿å…å†…å­˜æ³„æ¼

### 3. æ€§èƒ½ä¼˜åŒ–åŸåˆ™

- **æ‰¹å¤„ç†**: å¯¹é«˜é¢‘äº‹ä»¶è¿›è¡Œæ‰¹å¤„ç†
- **é€‰æ‹©è®¢é˜…**: åªè®¢é˜…å¿…è¦çš„äº‹ä»¶ç±»å‹
- **çŠ¶æ€ç®¡ç†**: åˆç†ç®¡ç†äº‹ä»¶å¤„ç†çŠ¶æ€

### 4. è°ƒè¯•å’Œç›‘æ§åŸåˆ™

- **äº‹ä»¶å†å²**: ä¿ç•™è¶³å¤Ÿçš„äº‹ä»¶å†å²ç”¨äºè°ƒè¯•
- **ç»Ÿè®¡ç›‘æ§**: å®šæœŸæ”¶é›†å’Œåˆ†æäº‹ä»¶ç»Ÿè®¡
- **é”™è¯¯è¿½è¸ª**: å®Œæ•´è®°å½•é”™è¯¯ä¸Šä¸‹æ–‡å’Œæ¢å¤è¿‡ç¨‹

é€šè¿‡å®Œå–„çš„LLMäº‹ä»¶å¤„ç†æœºåˆ¶ï¼ŒContinue-Reasoningå®ç°äº†å¯¹å¤§è¯­è¨€æ¨¡å‹äº¤äº’è¿‡ç¨‹çš„å…¨é¢ç®¡æ§å’Œä¼˜åŒ–ï¼Œæä¾›äº†è‰¯å¥½çš„ç”¨æˆ·ä½“éªŒå’Œç³»ç»Ÿå¯è§‚æµ‹æ€§ã€‚ 