import { BaseAgent, AgentOptions } from "../src/core/agent";
import { ContextManager } from "../src/core/context";
import { MapMemoryManager } from "../src/core/memory/baseMemory";
import { OPENAI_MODELS, ANTHROPIC_MODELS, GOOGLE_MODELS, GOOGLE_IMAGE_MODELS, GOOGLE_VIDEO_MODELS, SupportedModel, getModelProvider } from "../src/core/models";
import { LogLevel } from "../src/core/utils/logger";

/**
 * æ¨¡åž‹é€‰æ‹©ç¤ºä¾‹
 * å±•ç¤ºå¦‚ä½•ä½¿ç”¨æ–°çš„æ™ºèƒ½æ¨¡åž‹é…ç½®ç³»ç»Ÿ
 */

async function demonstrateModelSelection() {
    console.log("ðŸš€ æ¨¡åž‹é€‰æ‹©åŠŸèƒ½æ¼”ç¤º\n");

    // 1. åŸºæœ¬æ¨¡åž‹æ£€æµ‹
    console.log("=== 1. æ¨¡åž‹æä¾›å•†æ£€æµ‹ ===");
    const testModels: SupportedModel[] = [
        OPENAI_MODELS.GPT_4O,
        ANTHROPIC_MODELS.CLAUDE_3_5_SONNET_20241022, 
        GOOGLE_MODELS.GEMINI_2_5_FLASH_PREVIEW_05_20,
        OPENAI_MODELS.GPT_4_5_PREVIEW
    ];

    for (const model of testModels) {
        const provider = getModelProvider(model);
        console.log(`æ¨¡åž‹: ${model}`);
        console.log(`  æä¾›å•†: ${provider}`);
        console.log("");
    }

    // 2. ä¸åŒç±»åž‹çš„æ¨¡åž‹å±•ç¤º
    console.log("=== 2. ä¸åŒç±»åž‹çš„æ¨¡åž‹ ===");
    console.log(`æ–‡æœ¬æ¨¡åž‹: ${OPENAI_MODELS.GPT_4O} (${getModelProvider(OPENAI_MODELS.GPT_4O)})`);
    console.log(`éŸ³é¢‘æ¨¡åž‹: ${OPENAI_MODELS.GPT_4O_AUDIO_PREVIEW_2024_12_17} (${getModelProvider(OPENAI_MODELS.GPT_4O_AUDIO_PREVIEW_2024_12_17)})`);
    console.log(`å›¾åƒæ¨¡åž‹: ${GOOGLE_IMAGE_MODELS.IMAGEN_3_0_GENERATE_002} (${getModelProvider(GOOGLE_IMAGE_MODELS.IMAGEN_3_0_GENERATE_002)})`);
    console.log(`è§†é¢‘æ¨¡åž‹: ${GOOGLE_VIDEO_MODELS.VEO_2_0_GENERATE_001} (${getModelProvider(GOOGLE_VIDEO_MODELS.VEO_2_0_GENERATE_001)})`);
    console.log("");

    // 4. åˆ›å»ºä½¿ç”¨å…·ä½“æ¨¡åž‹çš„ Agent
    console.log("=== 4. åˆ›å»ºä¸åŒæ¨¡åž‹çš„ Agent ===");
    
    const contextManager = new ContextManager("demo-context", "Demo Context Manager", "Context manager for model selection demo", {});
    const memoryManager = new MapMemoryManager("demo-memory", "Demo Memory Manager", "Memory manager for model selection demo");

    // ç¤ºä¾‹ 1: ä½¿ç”¨æœ€æ–°çš„ GPT-4.5 æ¨¡åž‹
    const gpt45Options: AgentOptions = {
        model: OPENAI_MODELS.GPT_4_5_PREVIEW,
        temperature: 0.3,
        maxTokens: 4000,
        enableParallelToolCalls: true
    };

    const gpt45Agent = new BaseAgent(
        "gpt45-agent",
        "GPT-4.5 Agent",
        "ä½¿ç”¨æœ€æ–° GPT-4.5 æ¨¡åž‹çš„æ™ºèƒ½ä»£ç†",
        contextManager,
        memoryManager,
        [],
        10,
        LogLevel.INFO,
        gpt45Options
    );

    console.log("âœ… åˆ›å»º GPT-4.5 Agent æˆåŠŸ");

    // ç¤ºä¾‹ 2: ä½¿ç”¨ Claude 3.5 Sonnet æ¨¡åž‹
    const claudeOptions: AgentOptions = {
        model: ANTHROPIC_MODELS.CLAUDE_3_5_SONNET_20241022,
        temperature: 0.7,
        maxTokens: 8000
    };

    const claudeAgent = new BaseAgent(
        "claude-agent",
        "Claude 3.5 Agent", 
        "ä½¿ç”¨ Claude 3.5 Sonnet æ¨¡åž‹çš„æŽ¨ç†ä»£ç†",
        contextManager,
        memoryManager,
        [],
        10,
        LogLevel.INFO,
        claudeOptions
    );

    console.log("âœ… åˆ›å»º Claude 3.5 Agent æˆåŠŸ");

    // ç¤ºä¾‹ 3: ä½¿ç”¨ Gemini 2.5 Flash æ¨¡åž‹
    const geminiOptions: AgentOptions = {
        model: GOOGLE_MODELS.GEMINI_2_5_FLASH_PREVIEW_05_20,
        temperature: 0.5,
        maxTokens: 6000
    };

    const geminiAgent = new BaseAgent(
        "gemini-agent",
        "Gemini 2.5 Agent",
        "ä½¿ç”¨ Gemini 2.5 Flash æ¨¡åž‹çš„å¤šæ¨¡æ€ä»£ç†",
        contextManager,
        memoryManager,
        [],
        10,
        LogLevel.INFO,
        geminiOptions
    );

    console.log("âœ… åˆ›å»º Gemini 2.5 Agent æˆåŠŸ");

    // ç¤ºä¾‹ 4: ä½¿ç”¨éŸ³é¢‘æ¨¡åž‹
    const audioOptions: AgentOptions = {
        model: OPENAI_MODELS.GPT_4O_AUDIO_PREVIEW_2024_12_17,
        temperature: 0.8,
        enableParallelToolCalls: false
    };

    const audioAgent = new BaseAgent(
        "audio-agent",
        "Audio Agent",
        "ä½¿ç”¨éŸ³é¢‘æ¨¡åž‹çš„ä»£ç†",
        contextManager,
        memoryManager,
        [],
        10,
        LogLevel.INFO,
        audioOptions
    );

    console.log("âœ… åˆ›å»ºéŸ³é¢‘ Agent æˆåŠŸ");

    // ç¤ºä¾‹ 5: ä½¿ç”¨é»˜è®¤æ¨¡åž‹
    console.log("\n=== 5. ä½¿ç”¨é»˜è®¤æ¨¡åž‹ ===");
    const defaultOptions: AgentOptions = {
        // ä¸æŒ‡å®š modelï¼Œä½¿ç”¨é»˜è®¤çš„ GPT-4o
        temperature: 0.7
    };

    const defaultAgent = new BaseAgent(
        "default-agent",
        "Default Agent",
        "ä½¿ç”¨é»˜è®¤æ¨¡åž‹çš„ä»£ç†",
        contextManager,
        memoryManager,
        [],
        10,
        LogLevel.INFO,
        defaultOptions
    );

    console.log("âœ… é»˜è®¤æ¨¡åž‹åˆ›å»º Agent æˆåŠŸ");

    console.log("\nðŸŽ‰ æ¨¡åž‹é€‰æ‹©åŠŸèƒ½æ¼”ç¤ºå®Œæˆï¼");
}

/**
 * é«˜çº§ä½¿ç”¨åœºæ™¯ç¤ºä¾‹
 */
async function advancedUsageExamples() {
    console.log("\nðŸ”§ é«˜çº§ä½¿ç”¨åœºæ™¯\n");

    // åœºæ™¯ 1: å¤šæ¨¡æ€å·¥ä½œæµ
    console.log("=== åœºæ™¯ 1: å¤šæ¨¡æ€å·¥ä½œæµ ===");
    console.log("æ–‡æœ¬åˆ†æž â†’ å›¾åƒç”Ÿæˆ â†’ è§†é¢‘åˆ¶ä½œ");
    
    const textModel = OPENAI_MODELS.GPT_4O;
    const imageModel = GOOGLE_IMAGE_MODELS.IMAGEN_3_0_GENERATE_002;
    const videoModel = GOOGLE_VIDEO_MODELS.VEO_2_0_GENERATE_001;
    
    console.log(`1. æ–‡æœ¬åˆ†æž: ${textModel} (${getModelProvider(textModel)})`);
    console.log(`2. å›¾åƒç”Ÿæˆ: ${imageModel} (${getModelProvider(imageModel)})`);
    console.log(`3. è§†é¢‘åˆ¶ä½œ: ${videoModel} (${getModelProvider(videoModel)})`);

    // åœºæ™¯ 2: æˆæœ¬ä¼˜åŒ–é€‰æ‹©
    console.log("\n=== åœºæ™¯ 2: æˆæœ¬ä¼˜åŒ–é€‰æ‹© ===");
    console.log("æ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©åˆé€‚çš„æ¨¡åž‹:");
    
    const scenarios = [
        { task: "ç®€å•é—®ç­”", model: OPENAI_MODELS.GPT_4O_MINI },
        { task: "å¤æ‚æŽ¨ç†", model: OPENAI_MODELS.GPT_4_5_PREVIEW },
        { task: "ä»£ç ç”Ÿæˆ", model: ANTHROPIC_MODELS.CLAUDE_3_5_SONNET_20241022 },
        { task: "å®žæ—¶å¯¹è¯", model: OPENAI_MODELS.GPT_4O_REALTIME_PREVIEW_2024_12_17 }
    ];

    scenarios.forEach(scenario => {
        const provider = getModelProvider(scenario.model);
        console.log(`${scenario.task}: ${scenario.model} (${provider})`);
    });

    // åœºæ™¯ 3: åŠ¨æ€æ¨¡åž‹åˆ‡æ¢
    console.log("\n=== åœºæ™¯ 3: åŠ¨æ€æ¨¡åž‹åˆ‡æ¢ ===");
    console.log("æ ¹æ®ç”¨æˆ·è¾“å…¥ç±»åž‹åŠ¨æ€é€‰æ‹©æœ€ä½³æ¨¡åž‹");
    
    const inputTypes = [
        { input: "è¯­éŸ³æ¶ˆæ¯", recommended: OPENAI_MODELS.GPT_4O_AUDIO_PREVIEW_2024_12_17 },
        { input: "å›¾ç‰‡æè¿°è¯·æ±‚", recommended: GOOGLE_MODELS.GEMINI_2_5_FLASH_PREVIEW_05_20 },
        { input: "å¤æ‚é€»è¾‘é—®é¢˜", recommended: ANTHROPIC_MODELS.CLAUDE_3_5_SONNET_20241022 },
        { input: "ä»£ç è°ƒè¯•", recommended: OPENAI_MODELS.GPT_4_5_PREVIEW }
    ];

    inputTypes.forEach(type => {
        const provider = getModelProvider(type.recommended);
        console.log(`${type.input} â†’ ${type.recommended} (${provider})`);
    });

    console.log("\nâœ¨ é«˜çº§åœºæ™¯æ¼”ç¤ºå®Œæˆï¼");
}

// è¿è¡Œæ¼”ç¤º
if (require.main === module) {
    demonstrateModelSelection()
        .then(() => advancedUsageExamples())
        .catch(console.error);
} 